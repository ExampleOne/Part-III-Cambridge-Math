\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{float}
\usepackage{gensymb}
\usepackage{amsthm}
\usepackage{longtable}
\usepackage{adjustbox}
\usepackage{physics}
\usepackage[makeroom]{cancel}

\theoremstyle{definition}
\newtheorem{definition}{Definition}
\newtheorem{proposition}{Proposition}

\title{Statistical Field Theory}
\author{quinten tupker}
\date{October 9 2020 - \today}

\begin{document}

\maketitle

\section*{Introduction}

These notes are based on the course lectured by Dr Christopher E Thomas in
Michaelmas 2020. Due to the measures taken in the UK to limit the spread of
Covid-19, these lectures were delivered online. These are not meant to be an
accurate representation of what was lectures. They solely represent a mix of
what I thought was the most important part of the course, mixed in with many
(many) personal remarks, comments and digressions... Of course, any
corrections/comments are appreciated.

Statistical Field Theory is an extension of statistical physics. It assumes one
is familiar with statistical physics, and in particular, focuses on the study on
phase transitions. This course in particular follows David Tong's notes quite
closely.

\section{From Spin to Fields}

So why do we consider fields? Here we look at a model that shows the origin of
this connection.

\subsection{The Ising model}

The Ising model studies a lattice where each point on the lattice is assigned a
spin $S_i = \pm$. Consequently, the energy of the lattice is

$$ E = -B \sum_i S_i - J \sum_{<i, j>} S_i S_j $$

where $B$ is the external magnetic field strength, $J$ is the strength of
neighbour-neighbour interactions and $<i, j>$ is any nearest neighbour pair.
When $J > 0$, states tend to align (ferromagnetic behaviour) whereas if $J < 0$
states will prefer not to align (anti-ferromagnetic behaviour). We will focus on
the $J > 0$ case. But of course, due to heat there some statistical randomness,
and we want to include that. As such, we consider the canonical ensemble with
$\mathbb{P} (S_i) = e^{-\beta E(S_i)} / Z$ where $Z$ is the partition function,
$\beta = 1 / T$, and the Boltzmann constant $k_B = 1$. As ever in statistical
physics, we can derive everything from the partition function. Particularly
important in our case is the Free Energy, $F = \langle E \rangle - TS = -T \ln
(Z)$, and $dF = -S dT - p dV - M dB$ (so we can find S, p and M from F as well).

In statistical physics, we are particularly interested in the equilibrium state
(which occurs at the minimum of the free energy when temperature is constant),
and since we are looking at a magnetic system, we are particularly interested in
the equilibrium magnetisation. This can be calculated as

$$ m = \frac{1}{N} \sum_i \langle S_i \rangle = \frac{1}{N \beta} \partial_B
\ln(Z) $$

Now all that remains is to calculate $Z$ to find $m$. Unfortunately, in
dimension 3 or greater this is impossible (how impossible?), and it is still
hard in lower dimension. Consequently we take a different approach using the
so-called ``effective free energy'', which is defined such that

$$ \sum_m \sum_{\{S_i\} | m} e^{-\beta E[S_i]} = \sum_m e^{-\beta F(m)} $$

where $F(m)$ is the effective free energy. Since we can assume $N$ is large
(around $10^{23}$), we can then write18

$$ Z = N / 2 \int_{-1}^1 dm \, e^{-\beta F(m)}  = N / 2 \int_{-1}^1 dm \,
e^{-\beta N f(m)}$$

where $f(m) = F(m) / N$. From here, we can calculate the equilibrium field by
considering that since $N$ is large, the value contributing the most to the
integral is where $\partial_m f = 0$, and this is how the equilibrium $m$ is
calculated. This approach is called the \textbf{steepest descent approximation},
and we find here that $F_{\text{thermodynamic}} \approx F(m_{\text{min}})$.

This is all very well and nice, but the issue is that we still don't know how to
calculate $F(m)$, and it turns out that this is about as hard as calculating
$Z$. As such, we use the \textbf{mean field approximation}

$$ E \approx -B \sum_i m - J \sum_{<i, j>} m^2 = -BNm - \frac{1}{2} N J q m^2 $$

where $q = 2 \text{dim(space)}$ for a cubic latice in a space dimension dim.
Now,

$$ e^{-\beta N f(m)} = \sum e^{-\beta E(S_i) \approx \Omega(m) e^{-\beta
    E(m)}} $$

so in order to find $f(m)$ we need to know $\Omega(m)$ which is the number of
ways for a given energy state to occur, but since $m$ depends only on the number
of positive and negative spins states, $N_\uparrow, N_\downarrow$, and in
particular $N = N_\uparrow + N_\downarrow$ we see the number of total states is

$$ \ln(\Omega) = \ln \binom{N}{N_\uparrow} \approx N (\ln(2) - \frac{1}{2}(1 +
m) \ln(1 + m) - \frac{1}{2} (1 - m) \ln(1 - m)) $$

by Stirling's approximation. Consequently we find that

$$ f(m) \approx -Bm - \frac{1}{2} J q m^2 - \frac{1}{\beta} (\ln(2) -
\frac{1}{2} (1 + m) \ln(1 + m) - \frac{1}{2} (1 - m) \ln(1 - m)). $$

From here  by taking $\partial_m f = 0$, we find

$$ \beta(B + Jqm) = \frac{1}{2} \ln \left( \frac{1 + m}{1 - m} \right) $$

or equivalently

$$ m = \tanh(\beta (B + Jqm)). $$

From here, we can solve implicitly, but there is another approach we can take,
which is the way we will go about this. Just as a side note, we can see the
reason this is called the mean field approximation here as well: it is as if $m$
just shifts to external field to $B_{\text{eff}} = B + Jqm$. [End of lecture 1.]

\subsection{Landau Theory of Phase Transitions}

The remarkable part about the Ising model described above is not its
correctness. In fact, it is often incorrect, but rather its universality. It can
be applied in a wide variety of situations. As such, Landau tried to develop a
more general theory of phase transitions. Here we work through an extended
example to examine the general features of these. In particular, we study the
behaviour of the equilibrium $m_{\text{min}}$ when various quantities are varied.

From before, we can approximate $f$ for small $m$ as

$$ f(m) \approx \cancel{-\frac{1}{\beta} \ln(2)} - B m + \frac{1}{2} (\frac{1}{\beta} -
Jq) m^2 + \frac{1}{12\beta} m^4 + \dots $$

where we ignore the constant term since it does not affect anything. We start
with the $B = 0$ case where we find that

$$ f(m) = \frac{1}{2} (T - T_c) m^2 + \frac{1}{12} T^4 m^4  $$

where we define the \textbf{critical temperature} to be $Tc = Jq$. Then we get
the following scenarios.

\begin{figure}[H]
  \centering
  \includegraphics[width=5cm]{res/SFT/f_vs_m_high_T_B0}
  \caption{$T > T_c$}
  \label{figure: f_vs_m_high_T_B0}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=5cm]{res/SFT/f_vs_m_low_T_B0}
  \caption{$T < T_c$}
  \label{figure: f_vs_m_low_T_B0}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=5cm]{res/SFT/m_vs_T_B0}
  \caption{$m_{\text{min}}(T)$ for $B = 0$}
  \label{figure: m_vs_T_B0}
\end{figure}

The middle graph is meant to be symmetric, and we see here that $m_{\text{min}}$
can take two different values

$$ m_{\text{min}} = \pm m_0 = \pm \sqrt{\frac{3(T_c - T}{T}} $$

Now some definitions apply here. This is a \textbf{second order} or
\textbf{continuous} phase transition since $m$ is continuous in the quantity
being varied. $m = 0$ is called the \textbf{disordered phase}, and $m \neq 0$ is
called an \textbf{ordered phase}. \textbf{Spontaneous symmetry breaking} is what
we call the loss of symmetry in $m$ when $T$ decreases below $T_0$ (since $m$ is
forced to choose a positive or negative value). Finally, these terms all extend
to arbitrary \textbf{order parameter} $m$. We finally compute

$$ f(m_{\text{min}}) =
\begin{cases}
  0 & T > T_c \\
  -\frac{3}{4} \frac{(T_c - T)^2}{T} & T < T_c
\end{cases} $$

We can also look at the heat capacity here, and how that various with
temperature. Heat capacity may be defined as

$$ C = \partial_T \langle E \rangle = \beta^2 \partial_\beta^2 \ln(Z) $$

since recall that $\langle E \rangle = -\partial_\beta \ln(Z)$. Using $Z \approx
-\beta N f(m_{\text{min}})$ we find $c = C / N$ has

$$ c =
\begin{cases}
  0 & T \to T_c^+ \\
  3/2 & T \to T_c^-
\end{cases}
$$

so $c$ is a first order phase transition - ie. discontinuous.

The above scenario considered $B \neq 0$, but when $B = 0$ we get a different
situation. In particular, we do not get spontaneous symmetry breaking since the
system is no longer symmetric. In this case, the above graphs are skewed to the
right or the left unevenly leaving global minimum (the ``true'' minimum) and a
so-called \textbf{metastable} state.

Finally, we can observe another discontinuous phase transition when we study
$m_{\text{min}}$ as a function of $B$ at low $T$ ($T < T_c$). Since we're below
the critical temperature, the global minimum does not smoothly slide through 0,
but instead abruptly shifts from negative to postive (or the other way around)
giving a 1st order phase transition. Incidentally, I find this a bit odd, since
this really only makes sense in the 1D case, but as we will see later Mean Field
Theory (MFT) does not work in 1D. But in higher dimensions, $m$ is a vector and
instead of getting two local minima as above, we get a tilted (for $B \neq 0$)
circular valley where $f(m)$ is low. In this case, no phase transition occurs,
since the minimum just smoothly moves around this circular valley as $B$ is
varied...

\begin{figure}[H]
  \centering
  \includegraphics[width=10cm]{res/SFT/m_min_vs_B}
  \caption{$m_{\text{min}}$ vs $B$}
  \label{figure: m_min_vs_B}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=5cm]{res/SFT/f_vs_m_2d}
  \caption{$f(m)$ vs $m$ in 2D}
  \label{figure: f_vs_m_2d}
\end{figure}

Anyways, some other asymptotic behaviour includes that when $T \approx T_c$, we
get

$$ f(m) \approx -Bm + \frac{1}{12} T_c m^4 $$

leaving

$$ m \sim B^{1/3} $$

If we define magnetic susceptibility (the \textbf{response function} in this
context) to be $\chi = \partial_B m|_T$ we see that for $T > T_c$ we have

$$ f(m) \approx -Bm + \frac{1}{2} (T - T_c) m^2 + \dots $$

so

$$ m \approx \frac{B}{T - T_c} $$

so

$$ \chi \sim \frac{1}{T - T_c} $$

and for $T < T_c$

$$ \chi \sim \frac{1}{|T - T_c|} $$

\subsection{The Validity of MFT}

The purpose of all these calculations at the end of the last section is to find
some important set of numbers that we can use to check our theory with in the
real world. In particular, what we looked for were the \textbf{critical
  exponents}, which are

\begin{align*}
  m &\sim (T_c - T)^\beta & \beta &= 1/2 & T &< T_c \\
  c &\sim c_\pm |T - T_c|^{-\alpha} & \alpha &= 0 && \\
  \chi &\sim |T - T_c|^{-\gamma} & \gamma &= 1 && \\
  m &\sim B^{1/\delta} & \delta &= 3 &&
\end{align*}

in our worked example. Now for results, we find that in general, MFT fails
entirely below a certain \textbf{lower critical dimension}, $d_i$ and works correctly
above a certain \textbf{upper critical dimension}, $d_u$. In between it is structurally
accurate (can detect the right phase transitions) but inaccurate (finds the
wrong critical exponents). The Ising fails for dimension 1, gets the right
structure for dimensions 2 and 3, and works for dimension 4 and above. It is, as
expected, closer to the correct value for dimension 3 than for 2, but still can
be quite off.

Nevertheless, as mentioned earlier, the power of the MFT is not in its
correctness, but in its universality. Also, often structure is more important.
After all, if you can predict a phenomenon will happen, you can then carry out
an experiment to measure it more accurately. On the other hand, it is far harder
to use experiment to search for interesting phenomenon without knowing where to
look. So it is still quite powerful. Also, the fact that critical
exponents exist, and that critical points exist is a powerful bit of
universality that MFT gives.

To illustrate its universality, we can consider liquid-gas transitions. Here,
van der Waals analysis is completely off in its critical exponents, although it
does predict the correct type of phenomenon. However in three dimensions, the
Ising model agrees well. How do we implement the Ising model for a gas. Although
it's not at all obvious it will work, the implementation is actually quite
natural. Assume that a space consists of a lattice, and that every lattice is
assigned a value of 1 or 0 based on whether or not it is occupied by a particle.
Also assume that any point on the lattice can be occupied by no more than 1
particle at a time. Then we get

$$ E = -4J \sum_{<i j>} n_i n_j - \mu \sum n_i $$

We can proceed from there as usual. [End of lecture 2]

\end{document}